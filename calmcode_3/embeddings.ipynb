{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb40ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r9/680nx7m16m15hl407ftgfghm0000gn/T/ipykernel_65263/1625591897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "# Read data\n",
    "words = pd.read_csv('content/data/headlines.zip').loc[lambda d: ~d['text'].isna()]['text'][:20_000]\n",
    "\n",
    "def sliding_window(txt):\n",
    "    for i in range(len(txt) - 1):\n",
    "        txt = txt.replace(\" \", \"_\")\n",
    "        yield txt[i], txt[i + 1]\n",
    "\n",
    "# Make sliding window\n",
    "window = list(it.chain(*[sliding_window(_) for _ in words]))\n",
    "mapping = {c: i for i, c in enumerate(pd.DataFrame(window)[0].unique())}\n",
    "\n",
    "# Training data\n",
    "integers_in = np.array([mapping[w[0]] for w in window])\n",
    "integers_out = np.array([mapping[w[1]] for w in window]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c77c92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r9/680nx7m16m15hl407ftgfghm0000gn/T/ipykernel_65269/1842787351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_letters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# typically 36 -> 26 letters + 10 numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "num_letters = len(mapping) # typically 36 -> 26 letters + 10 numbers\n",
    "\n",
    "# this one is so we might grab the embeddings\n",
    "model_emb = Sequential()\n",
    "embedding = Embedding(num_letters, 2, input_length=1)\n",
    "model_emb.add(embedding)\n",
    "\n",
    "idx_to_calc = list(mapping.values())\n",
    "idx_to_calc = np.array([idx_to_calc]).T\n",
    "\n",
    "translator = {v:k for k,v in mapping.items()}\n",
    "# Generate the 2d embeddings on an untrained network\n",
    "preds = model_emb.predict(idx_to_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2d embeddings of each letter\n",
    "plt.scatter(preds[:, 0, 0], preds[:, 0, 1], alpha=0)\n",
    "for i, idx in enumerate(idx_to_calc):\n",
    "      plt.text(preds[i, 0, 0], preds[i, 0, 1], translator[idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c749af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# this one is so we might learn the mapping\n",
    "model_pred = Sequential()\n",
    "model_pred.add(embedding)\n",
    "model_pred.add(Flatten())\n",
    "model_pred.add(Dense(num_letters, activation=\"softmax\"))\n",
    "\n",
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model_pred.compile(adam, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "to_predict = OneHotEncoder(sparse=False).fit_transform(integers_out)\n",
    "model_pred.fit(integers_in, to_predict, epochs=1, verbose=1)\n",
    "\n",
    "preds = model_emb.predict(idx_to_calc)\n",
    "plt.scatter(preds[:, 0, 0], preds[:, 0, 1], alpha=0)\n",
    "for i, idx in enumerate(idx_to_calc):\n",
    "    plt.text(preds[i, 0, 0], preds[i, 0, 1], translator[idx[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
